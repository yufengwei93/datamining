# vector_db.py
import lancedb
import numpy as np
import os
import streamlit as st
from config import MILVUS_LITE_DATA_PATH, EMBEDDING_DIM, TOP_K, id_to_doc_map  # ğŸ‘ˆ è¡¥å……å¯¼å…¥

# LanceDB ä½¿ç”¨ç›®å½•ï¼ˆconfig.py å·²æ”¹ä¸º .lanceï¼Œæ— éœ€ replaceï¼‰
DB_DIR = MILVUS_LITE_DATA_PATH  # âœ… ç›´æ¥ä½¿ç”¨ï¼Œå› ä¸º config.py å·²æ˜¯ "./vector_db.lance"

@st.cache_resource
def get_milvus_client():
    try:
        abs_db_dir = os.path.abspath(MILVUS_LITE_DATA_PATH)
        os.makedirs(abs_db_dir, exist_ok=True)
        client = lancedb.connect(abs_db_dir)
        st.write(f"âœ… LanceDB client initialized at: {abs_db_dir}")
        return client
    except Exception as e:
        st.error(f"âŒ LanceDB åˆå§‹åŒ–å¤±è´¥: {type(e).__name__}: {e}")
        return None

@st.cache_resource
def setup_milvus_collection(_client):
    table_name = "medical_rag"
    try:
        _client.open_table(table_name)
        st.write("Found existing LanceDB table.")
        return True
    except (ValueError, FileNotFoundError):  # âœ… æ•è·ä¸¤ç§å¯èƒ½çš„å¼‚å¸¸
        import pyarrow as pa
        from config import EMBEDDING_DIM
        schema = pa.schema([
            pa.field("id", pa.int64()),
            pa.field("vector", pa.list_(pa.float32(), EMBEDDING_DIM)),
            pa.field("content_preview", pa.string())
        ])
        _client.create_table(table_name, schema=schema)
        st.write("Created LanceDB table.")
        return True

def index_data_if_needed(client, data, embedding_model):
    global id_to_doc_map
    table = client.open_table("medical_rag")
    
    # æ£€æŸ¥æ˜¯å¦å·²ç´¢å¼•ï¼ˆç®€åŒ–åˆ¤æ–­ï¼‰
    count = table.count_rows()
    if count > 0:
        st.write(f"Data already indexed ({count} rows).")
        return True

    # å‡†å¤‡æ•°æ®
    docs_for_embedding = []
    temp_id_map = {}
    data_to_insert = []

    for i, doc in enumerate(data):
        title = doc.get('title', '') or ""
        abstract = doc.get('abstract', '') or ""
        content = f"Title: {title}\nAbstract: {abstract}".strip()
        if not content:
            continue
        docs_for_embedding.append(content)
        # ğŸ‘‡ ç”¨ i ä½œä¸º IDï¼ˆæ•´æ•°ï¼‰
        temp_id_map[i] = {'title': title, 'abstract': abstract, 'content': content}
        data_to_insert.append({
            "id": i,
            "vector": [],  # å…ˆå ä½
            "content_preview": content[:500]
        })

    if not docs_for_embedding:
        st.error("No valid documents to index.")
        return False

    # ç”ŸæˆåµŒå…¥
    st.write(f"Embedding {len(docs_for_embedding)} documents...")
    embeddings = embedding_model.encode(docs_for_embedding, show_progress_bar=True)
    for i, emb in enumerate(embeddings):
        data_to_insert[i]["vector"] = emb.tolist()

    # æ’å…¥æ•°æ®
    st.write("Inserting into LanceDB...")
    table.add(data_to_insert)
    id_to_doc_map.update(temp_id_map)
    st.success(f"Indexed {len(data_to_insert)} documents.")
    return True

def search_similar_documents(client, query, embedding_model):
    table = client.open_table("medical_rag")
    query_vec = embedding_model.encode([query])[0].tolist()
    # LanceDB é»˜è®¤è¿”å›ç›¸ä¼¼åº¦ï¼ˆè¶Šé«˜è¶Šç›¸ä¼¼ï¼‰ï¼Œæˆ‘ä»¬è½¬ä¸ºè·ç¦»ï¼ˆè¶Šä½è¶Šç›¸ä¼¼ï¼‰
    results = table.search(query_vec).limit(TOP_K).to_list()  # ğŸ‘ˆ ç”¨ to_list() æ›´ç¨³å®š
    ids = [r["id"] for r in results]
    distances = [1 - r["_distance"] for r in results]  # ç›¸ä¼¼åº¦ â†’ è·ç¦»
    return ids, distances