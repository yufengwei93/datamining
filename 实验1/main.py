import os
import pandas as pd
import numpy as np
import re
from gensim.models import Word2Vec
from nltk.tokenize import word_tokenize
from tqdm import tqdm


# =============================
# è‡ªåŠ¨åˆ‡æ¢åˆ°è„šæœ¬æ‰€åœ¨ç›®å½•
# =============================
os.chdir(os.path.dirname(os.path.abspath(__file__)))
print("å½“å‰å·¥ä½œç›®å½•:", os.getcwd())


# =============================
# æ–‡æœ¬é¢„å¤„ç†
# =============================
def preprocess_text(text):
    if not isinstance(text, str):
        return []
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    return word_tokenize(text)


# =============================
# æ–‡æ¡£å‘é‡ = è¯å‘é‡å¹³å‡
# =============================
def get_document_vector(text, model):
    tokens = preprocess_text(text)
    vectors = [model.wv[t] for t in tokens if t in model.wv]
    if vectors:
        return np.mean(vectors, axis=0)
    return np.zeros(model.vector_size)


# =============================
# ä½™å¼¦ç›¸ä¼¼åº¦
# =============================
def cosine_sim(v1, v2):
    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-10)


# =============================
# ä¸»æµç¨‹ï¼šé‡æ–°è®­ç»ƒæ¨¡å‹ + ç›¸ä¼¼åº¦æµ‹è¯•
# =============================
def main():
    # ---------------------------------------
    # 1. åŠ è½½æ•°æ®é›† dev.csv
    # ---------------------------------------
    csv_path = "dataset/dev.csv"
    if not os.path.exists(csv_path):
        print("âŒ æ‰¾ä¸åˆ°æ•°æ®é›†:", csv_path)
        return

    print("\næ­£åœ¨åŠ è½½æ•°æ®...")
    df = pd.read_csv(csv_path)
    print("æ•°æ®å½¢çŠ¶:", df.shape)

    # åˆå¹¶ Title + Review
    title_series = df.iloc[:, 1].fillna("").astype(str)
    review_series = df.iloc[:, 2].fillna("").astype(str)
    texts = (title_series + " " + review_series).tolist()

    # ---------------------------------------
    # 2. æ–‡æœ¬é¢„å¤„ç†
    # ---------------------------------------
    print("\né¢„å¤„ç†æ–‡æœ¬...")
    corpus = [preprocess_text(t) for t in tqdm(texts)]

    # ---------------------------------------
    # 3. è®­ç»ƒ Word2Vecï¼ˆé‡æ–°è®­ç»ƒï¼Œé¿å… numpy ä¸å…¼å®¹ï¼‰
    # ---------------------------------------
    print("\næ­£åœ¨è®­ç»ƒ Word2Vec æ¨¡å‹...")
    model = Word2Vec(
        sentences=corpus,
        vector_size=128,
        window=3,
        min_count=5,
        workers=16,
        epochs=5
    )

    # ä¿å­˜æ¨¡å‹
    model.save("word2vec_dev.model")
    print("æ¨¡å‹å·²ä¿å­˜ä¸º word2vec_dev.model")

    # ---------------------------------------
    # 4. ç”Ÿæˆæ–‡æ¡£å‘é‡ï¼ˆä»…ç”¨äºç›¸ä¼¼åº¦ç¤ºä¾‹ï¼‰
    # ---------------------------------------
    print("\nç”Ÿæˆæ–‡æ¡£å‘é‡...")
    vectors = [get_document_vector(t, model) for t in tqdm(texts[:20])]  # åªå–å‰ 20 æ¡ç¤ºä¾‹

    # ---------------------------------------
    # 5. ç¤ºä¾‹ï¼šå–ç¬¬ 0 å’Œç¬¬ 1 æ¡è¯„è®ºè®¡ç®—ç›¸ä¼¼åº¦
    # ---------------------------------------
    text1 = texts[0]
    text2 = texts[1]
    sim = cosine_sim(vectors[0], vectors[1])

    print("\n==============================")
    print("ç¤ºä¾‹ç›¸ä¼¼åº¦è®¡ç®—ç»“æœï¼š")
    print("==============================")
    print("æ–‡æœ¬ 1ï¼š", text1)
    print("æ–‡æœ¬ 2ï¼š", text2)
    print(f"\nå‘é‡ç›¸ä¼¼åº¦: {sim:.4f}")
    print("\nğŸ‰ å®Œæˆï¼")


if __name__ == "__main__":
    main()
